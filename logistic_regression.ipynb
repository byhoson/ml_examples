{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXwinnJjtYA4cegs2FBkKE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byhoson/ml_examples/blob/master/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asyL9vYjV1OW",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/logistic-regression-explained-and-implemented-in-python-880955306060"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pcdCcKwT3_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0NxPQGiZ-xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model settings\n",
        "x_dim = 2\n",
        "lr = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZsjqEVockje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_toy_data(size):\n",
        "    x0 = np.random.normal(size=2*size).reshape(-1, 2) - 1\n",
        "    x1 = np.random.normal(size=2*size).reshape(-1, 2) + 1.\n",
        "    return np.concatenate([x0, x1]), np.concatenate([np.zeros(size), np.ones(size)]).astype(np.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li8upWBzdbSG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "8810f14c-bacc-495e-ec6f-d4cde87b10eb"
      },
      "source": [
        "# prepare the data\n",
        "x,y = generate_toy_data(10)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.19012606 -2.22622386]\n",
            " [-2.04049405 -2.44751081]\n",
            " [-0.45409877  0.62979237]\n",
            " [-1.22362509 -0.68293164]\n",
            " [-2.4312614  -2.53874673]\n",
            " [-2.16945629 -0.75316156]\n",
            " [-0.50686355 -0.51116417]\n",
            " [-0.11469152 -1.22612155]\n",
            " [ 0.46647085 -0.95809234]\n",
            " [-1.27418237  0.67897371]\n",
            " [ 0.60397342  1.16668821]\n",
            " [ 2.11006207  0.78876538]\n",
            " [ 2.06181201  1.53727557]\n",
            " [-0.53003099  1.34142911]\n",
            " [ 0.59658391  2.10941091]\n",
            " [-0.11917394  0.24749154]\n",
            " [ 1.33739318  2.34437102]\n",
            " [-0.52182908  0.19253854]\n",
            " [ 0.67493564  0.88525717]\n",
            " [-0.09007521  1.29381909]]\n",
            "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV2LledmUGet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+np.e**(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9dgbiMrWFJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(w,b,X):\n",
        "  \"\"\"\n",
        "    returns the prediction of a single input\n",
        "    arguments:\n",
        "      w -- weights of size [x_dim]\n",
        "      b -- bias, a scalar\n",
        "      X -- input data of size [batch, x_dim]\n",
        "    returns:\n",
        "      sigmoid(z) -- probability of being in class 1\n",
        "  \"\"\"\n",
        "  z = b + np.matmul(w,X.T)\n",
        "  return sigmoid(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGXKo5YXUIog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize(w,b,X,y,y_hat,lr=0.001):\n",
        "  \"\"\"\n",
        "    optimize one step\n",
        "    arguments:\n",
        "      w -- weights of size [x_dim]\n",
        "      b -- bias, a scalar\n",
        "      X -- input data of size [batch, x_dim]\n",
        "      y -- labels of size [batch]\n",
        "      y_hat -- predictions of size [batch]\n",
        "      lr -- learning rate(default = 0.001)\n",
        "    returns:\n",
        "      w -- optimized weights\n",
        "      b -- optimized bias\n",
        "  \"\"\"\n",
        "  bsize = len(y)\n",
        "  # dw -- gradient of w\n",
        "  # TODO: deal with the X multiplied at the end! -- need to use vector calculus\n",
        "  dw = np.zeros_like(w)\n",
        "  for i in range(len(dw)):\n",
        "    dw[i] = -2/bsize*np.sum((y-y_hat)*y_hat*(1-y_hat)*X[:,i])\n",
        "  # db = get derivative at b\n",
        "  db = -2/bsize*np.sum((y-y_hat)*y_hat*(1-y_hat))\n",
        "  # take a step\n",
        "  w = w - lr * dw\n",
        "  b = b - lr * db\n",
        "  return w,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5nj7ZsbUYyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(y,y_hat):\n",
        "  return np.sum((y-y_hat)**2)/len(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW7UlCELU1re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(w,b,x,epoch,lr=0.001):\n",
        "  for _ in range(epoch):\n",
        "    y_hat = forward(w,b,x)\n",
        "    print(loss(y,y_hat))\n",
        "    w,b = optimize(w,b,x,y,y_hat,lr=lr)\n",
        "  return w,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n81janxXn4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(w,x):\n",
        "  \"\"\"\n",
        "  returns the array of predicted values\n",
        "  \"\"\"\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwlRi9GMdhVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42c7cb56-4ade-43b0-80ff-ef6160402ce0"
      },
      "source": [
        "# initialize model by 0\n",
        "weights = np.zeros(x_dim)\n",
        "bias = 0.\n",
        "print(weights, bias)\n",
        "# train the model\n",
        "weights, bias = train(weights,bias,x,100,lr=0.2)\n",
        "weights, bias = train(weights,bias,x,100,lr=0.01)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0.] 0.0\n",
            "0.25\n",
            "0.22326226807798485\n",
            "0.20064987984579435\n",
            "0.1817753890048532\n",
            "0.1660807208443218\n",
            "0.15299599770299083\n",
            "0.14201669289067592\n",
            "0.13272649500409636\n",
            "0.12479364754244164\n",
            "0.11795781246872324\n",
            "0.11201557803640168\n",
            "0.1068076937790344\n",
            "0.1022087892965728\n",
            "0.0981194279362996\n",
            "0.09446007924617272\n",
            "0.09116657844296822\n",
            "0.08818670704137942\n",
            "0.08547760868737883\n",
            "0.0830038249467153\n",
            "0.0807357918643862\n",
            "0.07864868040916098\n",
            "0.07672149507146898\n",
            "0.07493636757892207\n",
            "0.07327799916742121\n",
            "0.07173321681099723\n",
            "0.07029061753281993\n",
            "0.06894028130503052\n",
            "0.06767353774868032\n",
            "0.06648277533245706\n",
            "0.06536128437212292\n",
            "0.0643031270892917\n",
            "0.06330302946910996\n",
            "0.06235629078493682\n",
            "0.06145870752388295\n",
            "0.06060650911560065\n",
            "0.05979630338623735\n",
            "0.059025030065668324\n",
            "0.058289920995623676\n",
            "0.05758846593906525\n",
            "0.05691838309220783\n",
            "0.05627759356134258\n",
            "0.05566419919583967\n",
            "0.05507646327307736\n",
            "0.054512793615752154\n",
            "0.053971727791081114\n",
            "0.05345192009795481\n",
            "0.05295213009460002\n",
            "0.05247121245770353\n",
            "0.05200810799577164\n",
            "0.05156183566597892\n",
            "0.05113148546586852\n",
            "0.05071621208979545\n",
            "0.050315229255582\n",
            "0.04992780461999565\n",
            "0.04955325521278011\n",
            "0.049190943328409016\n",
            "0.04884027282276594\n",
            "0.04850068576881451\n",
            "0.04817165943119329\n",
            "0.04785270352471118\n",
            "0.04754335772605407\n",
            "0.04724318941175672\n",
            "0.046951791598727206\n",
            "0.04666878106641643\n",
            "0.046393796642160395\n",
            "0.04612649763334434\n",
            "0.04586656239188715\n",
            "0.04561368699816333\n",
            "0.04536758405289569\n",
            "0.04512798156679654\n",
            "0.044894621938828906\n",
            "0.04466726101492215\n",
            "0.04444566721982836\n",
            "0.04422962075555597\n",
            "0.04401891286048486\n",
            "0.04381334512385628\n",
            "0.043612728850857076\n",
            "0.04341688447398363\n",
            "0.04322564100678839\n",
            "0.04303883553648206\n",
            "0.0428563127521977\n",
            "0.042677924506019774\n",
            "0.04250352940414734\n",
            "0.04233299242580025\n",
            "0.04216618456769183\n",
            "0.042002982512084806\n",
            "0.04184326831662176\n",
            "0.041686929124278155\n",
            "0.0415338568919284\n",
            "0.04138394813614326\n",
            "0.04123710369495343\n",
            "0.04109322850441941\n",
            "0.04095223138894287\n",
            "0.04081402486434202\n",
            "0.04067852495279188\n",
            "0.04054565100880253\n",
            "0.0404153255554732\n",
            "0.04028747413032038\n",
            "0.04016202514003202\n",
            "0.040038909723549565\n",
            "0.039918061622925424\n",
            "0.03991210362171039\n",
            "0.03990615105962779\n",
            "0.039900203929029716\n",
            "0.03989426222228255\n",
            "0.03988832593176698\n",
            "0.0398823950498778\n",
            "0.039876469569024145\n",
            "0.039870549481629186\n",
            "0.03986463478013029\n",
            "0.03985872545697891\n",
            "0.03985282150464052\n",
            "0.03984692291559469\n",
            "0.03984102968233491\n",
            "0.039835141797368696\n",
            "0.03982925925321746\n",
            "0.03982338204241652\n",
            "0.03981751015751504\n",
            "0.039811643591076105\n",
            "0.03980578233567646\n",
            "0.03979992638390674\n",
            "0.03979407572837127\n",
            "0.03978823036168806\n",
            "0.039782390276488847\n",
            "0.03977655546541897\n",
            "0.039770725921137395\n",
            "0.03976490163631668\n",
            "0.03975908260364288\n",
            "0.03975326881581566\n",
            "0.03974746026554805\n",
            "0.03974165694556665\n",
            "0.03973585884861143\n",
            "0.03973006596743574\n",
            "0.03972427829480633\n",
            "0.03971849582350322\n",
            "0.03971271854631982\n",
            "0.03970694645606274\n",
            "0.039701179545551836\n",
            "0.03969541780762023\n",
            "0.03968966123511414\n",
            "0.03968390982089301\n",
            "0.03967816355782935\n",
            "0.039672422438808794\n",
            "0.03966668645672996\n",
            "0.03966095560450461\n",
            "0.03965522987505741\n",
            "0.03964950926132607\n",
            "0.03964379375626115\n",
            "0.03963808335282621\n",
            "0.03963237804399761\n",
            "0.03962667782276462\n",
            "0.03962098268212932\n",
            "0.03961529261510656\n",
            "0.03960960761472397\n",
            "0.03960392767402191\n",
            "0.03959825278605345\n",
            "0.039592582943884305\n",
            "0.03958691814059289\n",
            "0.03958125836927021\n",
            "0.03957560362301983\n",
            "0.039569953894957946\n",
            "0.03956430917821321\n",
            "0.03955866946592682\n",
            "0.039553034751252464\n",
            "0.039547405027356236\n",
            "0.03954178028741667\n",
            "0.039536160524624706\n",
            "0.039530545732183606\n",
            "0.039524935903309\n",
            "0.0395193310312288\n",
            "0.03951373110918324\n",
            "0.039508136130424754\n",
            "0.03950254608821803\n",
            "0.039496960975839934\n",
            "0.03949138078657953\n",
            "0.03948580551373796\n",
            "0.03948023515062855\n",
            "0.03947466969057668\n",
            "0.03946910912691979\n",
            "0.03946355345300736\n",
            "0.03945800266220083\n",
            "0.03945245674787369\n",
            "0.039446915703411335\n",
            "0.039441379522211065\n",
            "0.03943584819768213\n",
            "0.03943032172324561\n",
            "0.03942480009233444\n",
            "0.03941928329839341\n",
            "0.03941377133487898\n",
            "0.039408264195259515\n",
            "0.039402761873015044\n",
            "0.03939726436163731\n",
            "0.03939177165462977\n",
            "0.0393862837455075\n",
            "0.03938080062779722\n",
            "0.03937532229503727\n",
            "0.039369848740777584\n",
            "0.039364379958579596\n",
            "0.039358915942016306\n",
            "0.039353456684672244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WEwqq6td3Q4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8b21457e-870d-4999-c301-f30749495279"
      },
      "source": [
        "w0 = np.array([1.,2.])\n",
        "b0 = 2.\n",
        "x0 = np.array([[1.,2.],[3.,4.]])\n",
        "forward(w0,b0,x0)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 7. 13.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99908895, 0.99999774])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC4OJx_9pApM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}